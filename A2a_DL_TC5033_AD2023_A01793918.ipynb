{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Handrum/ML_Equipo_6/blob/main/A2a_DL_TC5033_AD2023_A01793918.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">\n",
        "![Evidence 3](https://i.imgur.com/mu6ZuGT.jpg)\n",
        "\n",
        "# **Master's in Applied Artificial Intelligence**\n",
        "## **Course: Advanced Machine Learning Methods**\n",
        "* ### **Lead Instructor**: José Antonio Cantoral Ceballos\n",
        "* **Tutor**: Ana Bricia Galindo\n",
        "\n",
        "## **Actividad 2a: Implementación de un FC para un conjunto de datos ASL usando PyTorch**\n",
        "\n",
        "*   --> Helmy Andrea Moreno Navarro | A01793918"
      ],
      "metadata": {
        "id": "S9xsNSmn4OzJ"
      },
      "id": "S9xsNSmn4OzJ"
    },
    {
      "cell_type": "markdown",
      "id": "601b2309",
      "metadata": {
        "id": "601b2309"
      },
      "source": [
        "# TC 5033\n",
        "## **Deep Learning**\n",
        "## **Fully Connected Deep Neural Networks using PyTorch**\n",
        "<br>\n",
        "\n",
        "#### **Activity 2a**: Implementing a FC for ASL Dataset using PyTorch\n",
        "<br>\n",
        "\n",
        "\n",
        "- **Objective**\n",
        "\n",
        "    The primary aim of this activity is to transition from using Numpy for network implementation to utilizing PyTorch, a powerful deep learning framework. You will be replicating the work you did for the ASL dataset in Activity 1b, but this time, you'll implement a your multi layer FC model using PyTorch.\n",
        "    \n",
        "- **Instructions**\n",
        "\n",
        "    **Review Previous Work**: Begin by reviewing your Numpy-based Fully Connected Network for the ASL dataset from Activity 1b. Note the architecture, hyperparameters, and performance metrics for comparison.\n",
        "\n",
        "    **Introduce PyTorch**: If you're new to PyTorch, take some time to familiarize yourself with its basic operations and syntax. You can consult the official documentation or follow online tutorials.\n",
        "\n",
        "    **Prepare the ASL Dataset**: As before, download and preprocess the Kaggle ASL dataset.\n",
        "\n",
        "    **Implement the Network**: Design your network architecture tailored for the ASL dataset. Pay special attention to PyTorch modules like nn.Linear() and nn.ReLU().\n",
        "\n",
        "    **Train the Model**: Implement the training loop, making use of PyTorch's autograd to handle backpropagation. Monitor metrics like loss and accuracy as the model trains.\n",
        "\n",
        "    **Analyze and Document**: In Markdown cells, discuss the architecture choices, any differences in performance between the Numpy and PyTorch implementations, and insights gained from using a deep learning framework like PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Import of libraries**"
      ],
      "metadata": {
        "id": "ppMagkHyr0nB"
      },
      "id": "ppMagkHyr0nB"
    },
    {
      "cell_type": "code",
      "source": [
        "#jupyterthemes installation in case you need to use this module\n",
        "!pip install jupyterthemes"
      ],
      "metadata": {
        "id": "k4fZXjUlvWS4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "968d7a9d-73d1-4b30-cb52-69b1b3f385cf"
      },
      "id": "k4fZXjUlvWS4",
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: jupyterthemes in /usr/local/lib/python3.10/dist-packages (0.20.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from jupyterthemes) (5.4.0)\n",
            "Requirement already satisfied: notebook>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from jupyterthemes) (6.5.5)\n",
            "Requirement already satisfied: ipython>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from jupyterthemes) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from jupyterthemes) (3.7.1)\n",
            "Requirement already satisfied: lesscpy>=0.11.2 in /usr/local/lib/python3.10/dist-packages (from jupyterthemes) (0.15.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.4.1->jupyterthemes) (4.8.0)\n",
            "Requirement already satisfied: ply in /usr/local/lib/python3.10/dist-packages (from lesscpy>=0.11.2->jupyterthemes) (3.11)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=1.4.3->jupyterthemes) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (3.1.2)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (6.3.2)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (6.1.12)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.2.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (5.9.2)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (6.5.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (1.5.8)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (5.5.6)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (0.17.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=5.6.0->jupyterthemes) (1.0.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->jupyterthemes) (3.11.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.4.1->jupyterthemes) (0.8.3)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (0.2.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.8.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=5.6.0->jupyterthemes) (1.2.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (2.18.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=5.6.0->jupyterthemes) (4.19.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.4.1->jupyterthemes) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.4.1->jupyterthemes) (0.2.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.3->jupyterthemes) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=5.6.0->jupyterthemes) (21.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=5.6.0->jupyterthemes) (0.10.4)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.6.4)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=5.6.0->jupyterthemes) (0.5.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=5.6.0->jupyterthemes) (1.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=5.6.0->jupyterthemes) (2.21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "id": "183db241",
      "metadata": {
        "id": "183db241"
      },
      "outputs": [],
      "source": [
        "#Import of libraries to be used to implement fully connected deep neural networks using PyTorch models.\n",
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "%matplotlib inline\n",
        "\n",
        "#PyTorch stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Solamente para usuarios de Jupyter Themes\n",
        "from jupyterthemes import jtplot\n",
        "jtplot.style(grid=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 194,
      "id": "b3896ddf",
      "metadata": {
        "id": "b3896ddf"
      },
      "outputs": [],
      "source": [
        "##Data is loaded from local\n",
        "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
        "DATA_PATH = '/content/asl_data/'\n",
        "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
        "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08fa938e",
      "metadata": {
        "id": "08fa938e"
      },
      "source": [
        "### **Always a good idea to explore the data**\n",
        "\n",
        "Our dataset contains: 27455 rows × 784 columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 195,
      "id": "c149b4d7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "c149b4d7",
        "outputId": "b17d3f89-b324-4863-cd15-591204a207c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
              "0      3     107     118     127     134     139     143     146     150   \n",
              "1      6     155     157     156     156     156     157     156     158   \n",
              "2      2     187     188     188     187     187     186     187     188   \n",
              "3      2     211     211     212     212     211     210     211     210   \n",
              "4     12     164     167     170     172     176     179     180     184   \n",
              "\n",
              "   pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
              "0     153  ...       207       207       207       207       206       206   \n",
              "1     158  ...        69       149       128        87        94       163   \n",
              "2     187  ...       202       201       200       199       198       199   \n",
              "3     210  ...       235       234       233       231       230       226   \n",
              "4     185  ...        92       105       105       108       133       163   \n",
              "\n",
              "   pixel781  pixel782  pixel783  pixel784  \n",
              "0       206       204       203       202  \n",
              "1       175       103       135       149  \n",
              "2       198       195       194       195  \n",
              "3       225       222       229       163  \n",
              "4       157       163       164       179  \n",
              "\n",
              "[5 rows x 785 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d6af4d2c-5008-4251-8bf6-e6a6fa2b4b25\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>107</td>\n",
              "      <td>118</td>\n",
              "      <td>127</td>\n",
              "      <td>134</td>\n",
              "      <td>139</td>\n",
              "      <td>143</td>\n",
              "      <td>146</td>\n",
              "      <td>150</td>\n",
              "      <td>153</td>\n",
              "      <td>...</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>207</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>206</td>\n",
              "      <td>204</td>\n",
              "      <td>203</td>\n",
              "      <td>202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>155</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>156</td>\n",
              "      <td>157</td>\n",
              "      <td>156</td>\n",
              "      <td>158</td>\n",
              "      <td>158</td>\n",
              "      <td>...</td>\n",
              "      <td>69</td>\n",
              "      <td>149</td>\n",
              "      <td>128</td>\n",
              "      <td>87</td>\n",
              "      <td>94</td>\n",
              "      <td>163</td>\n",
              "      <td>175</td>\n",
              "      <td>103</td>\n",
              "      <td>135</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>187</td>\n",
              "      <td>186</td>\n",
              "      <td>187</td>\n",
              "      <td>188</td>\n",
              "      <td>187</td>\n",
              "      <td>...</td>\n",
              "      <td>202</td>\n",
              "      <td>201</td>\n",
              "      <td>200</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>199</td>\n",
              "      <td>198</td>\n",
              "      <td>195</td>\n",
              "      <td>194</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>211</td>\n",
              "      <td>211</td>\n",
              "      <td>212</td>\n",
              "      <td>212</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>211</td>\n",
              "      <td>210</td>\n",
              "      <td>210</td>\n",
              "      <td>...</td>\n",
              "      <td>235</td>\n",
              "      <td>234</td>\n",
              "      <td>233</td>\n",
              "      <td>231</td>\n",
              "      <td>230</td>\n",
              "      <td>226</td>\n",
              "      <td>225</td>\n",
              "      <td>222</td>\n",
              "      <td>229</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>164</td>\n",
              "      <td>167</td>\n",
              "      <td>170</td>\n",
              "      <td>172</td>\n",
              "      <td>176</td>\n",
              "      <td>179</td>\n",
              "      <td>180</td>\n",
              "      <td>184</td>\n",
              "      <td>185</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>105</td>\n",
              "      <td>105</td>\n",
              "      <td>108</td>\n",
              "      <td>133</td>\n",
              "      <td>163</td>\n",
              "      <td>157</td>\n",
              "      <td>163</td>\n",
              "      <td>164</td>\n",
              "      <td>179</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d6af4d2c-5008-4251-8bf6-e6a6fa2b4b25')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d6af4d2c-5008-4251-8bf6-e6a6fa2b4b25 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d6af4d2c-5008-4251-8bf6-e6a6fa2b4b25');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4bef12ec-7cc6-433e-a3dc-a0ccba77d9fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4bef12ec-7cc6-433e-a3dc-a0ccba77d9fa')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4bef12ec-7cc6-433e-a3dc-a0ccba77d9fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bf2d1df",
      "metadata": {
        "id": "8bf2d1df"
      },
      "source": [
        "### **Get training label data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 196,
      "id": "4348519c",
      "metadata": {
        "id": "4348519c"
      },
      "outputs": [],
      "source": [
        "#End result of this code is 4 variables (y_train, y_val, x_train, x_val):\n",
        "y_train = np.array(train_df['label']) #labels for training\n",
        "y_val = np.array(valid_df['label']) #labels for validation\n",
        "del train_df['label']\n",
        "del valid_df['label']\n",
        "x_train = train_df.values.astype(np.float32) #features for training\n",
        "x_val = valid_df.values.astype(np.float32) #characteristics for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 197,
      "id": "6c9bed68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6c9bed68",
        "outputId": "f63b2852-c1e2-4caa-93f2-95fc6eeffe36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27455, 784)\n",
            "(27455,)\n"
          ]
        }
      ],
      "source": [
        "#Data is printed\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "id": "ea87a153",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ea87a153",
        "outputId": "4095ab4d-1f45-4d1d-f214-00540440f253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7172, 784) (7172,)\n"
          ]
        }
      ],
      "source": [
        "#Check the number of examples in the feature set matches the number of labels\n",
        "#to avoid errors when training models\n",
        "#x_val.shape returns (7172, 784 | 7172 validation examples, each with 784 features)\n",
        "#y_val.shape returns (7172 matching labels)\n",
        "print(x_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proposes of function **split_val_tes**\n",
        "\n",
        "- This function proposes to split the data and labels (x, y, respectively) into two subsets based on the percentage specified by the pct parameter. The function has the ability to randomly shuffle the data before performing the split if the shuffle flag is set.\n",
        "\n",
        "The function returns **four values**:\n",
        "* The **data** and **labels** of the first subset,\n",
        "* and the **data** and **labels** of the second subset.\n",
        "\n",
        "Definition of the split_val_test function with **parameters**:\n",
        "- **x**: input data\n",
        "- **y**: labels corresponding to x\n",
        "- **pct**: split percentage (by default 0.5, which means 50%)"
      ],
      "metadata": {
        "id": "Xyyoi0Hi5px2"
      },
      "id": "Xyyoi0Hi5px2"
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "id": "7b7edd3e",
      "metadata": {
        "id": "7b7edd3e"
      },
      "outputs": [],
      "source": [
        "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
        "\n",
        "    # Ensure that the number of samples in x is equal to the number of samples in y\n",
        "    assert x.shape[0] == y.shape[0], 'Number of samples x!= number samples y'\n",
        "    total_samples = x.shape[0] # Obtener el número total de muestras\n",
        "\n",
        "    if shuffle: # shuffle: a flag to decide whether to shuffle the data before splitting (default True)\n",
        "        idxs = np.arange(x.shape[0]) # Create an array of indexes from 0 to the length of x\n",
        "        np.random.shuffle(idxs) # Mix the index array\n",
        "\n",
        "        # Rearrange x and y using the mixed indexes\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]\n",
        "        #return x_val, y_val, x_test, y_test\n",
        "#         return x[:total_samples//2, :], y[:total_samples//2], x[total_samples//2:, :], y[total_samples//2:]\n",
        "\n",
        "    # Divide x and y based on the specified percentage and return the two subsets\n",
        "    return x[:int(total_samples*pct), :], y[:int(total_samples*pct)], x[int(total_samples*(pct)):, :], y[int(total_samples*(pct)):]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "id": "6fb6fda2",
      "metadata": {
        "id": "6fb6fda2"
      },
      "outputs": [],
      "source": [
        "# It splits the existing validation set into two new sets: validation and test.\n",
        "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "id": "e7a02137",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e7a02137",
        "outputId": "8c41df0f-062b-479d-a551-9f21d6a7b5d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ],
      "source": [
        "#Determine the data type or class of the variable y_val.\n",
        "type(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "id": "986ec106",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "986ec106",
        "outputId": "11dd3112-7bdd-4f72-c002-fcd6357dd2f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3586, 784) (3586,)\n",
            "(3586, 784) (3586,)\n"
          ]
        }
      ],
      "source": [
        "print(x_val.shape, y_val.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Created list**\n",
        "A list is created with all the letters of the lowercase English alphabet (which originally has 26 letters) and then the letters 'j' and 'z' are removed."
      ],
      "metadata": {
        "id": "qexPVLfZBnGS"
      },
      "id": "qexPVLfZBnGS"
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "id": "d65bdf4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d65bdf4c",
        "outputId": "8cbde4c0-6dc5-4ae0-b8de-6b1cd64ac135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n"
          ]
        }
      ],
      "source": [
        "alphabet=list(string.ascii_lowercase) # We create a list called 'alphabet' that contains all the lowercase letters of the English alphabet.\n",
        "alphabet.remove('j') # Eliminamos la letra 'j' and \"z\" de la lista 'alphabet'.\n",
        "alphabet.remove('z')\n",
        "print(len(alphabet)) # Imprimimos la longitud actual de la lista 'alphabet'."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f17874be",
      "metadata": {
        "id": "f17874be"
      },
      "source": [
        "### **Normalise the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Parameters:**\n",
        "\n",
        "* **x_mean**: This represents the mean (average) of the data.\n",
        "* **x_std**: This stands for the standard deviation of the data.\n",
        "* **x_data**: This is the actual data that you want to normalize.\n",
        "\n",
        "The purpose of this function is to ensure that the data will be at a mean of 0 and a standard deviation of 1 after normalization."
      ],
      "metadata": {
        "id": "cGxTL-X7CaiJ"
      },
      "id": "cGxTL-X7CaiJ"
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "id": "b0a5cce2",
      "metadata": {
        "id": "b0a5cce2"
      },
      "outputs": [],
      "source": [
        "def normalise(x_mean, x_std, x_data):\n",
        "    return (x_data - x_mean) / x_std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "id": "b8cf6d30",
      "metadata": {
        "id": "b8cf6d30"
      },
      "outputs": [],
      "source": [
        "x_mean = x_train.mean()\n",
        "x_std = x_train.std()\n",
        "\n",
        "x_train = normalise(x_mean, x_std, x_train)\n",
        "x_val = normalise(x_mean, x_std, x_val)\n",
        "x_test = normalise(x_mean, x_std, x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "id": "d0eef77a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d0eef77a",
        "outputId": "22ed87b9-7691-4fee-fff7-0f51e80b961e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.6268384e-06, 0.99999946)"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ],
      "source": [
        "x_train.mean(), x_train.std()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Graphing the data**"
      ],
      "metadata": {
        "id": "6_ggDhz8DeQ6"
      },
      "id": "6_ggDhz8DeQ6"
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "id": "4761728d",
      "metadata": {
        "id": "4761728d"
      },
      "outputs": [],
      "source": [
        "def plot_number(image):\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "id": "e5eb103d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e5eb103d",
        "outputId": "513254ae-1dbf-42dc-ea2a-343744b355e6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 208
        }
      ],
      "source": [
        "type(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "id": "1b9216b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "1b9216b0",
        "outputId": "4e25c500-deb4-42a9-d2d8-9279e744faa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sampled image represents a: b\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "rnd_idx = np.random.randint(len(y_val))\n",
        "# print(rnd_idx)\n",
        "# print(y_val[rnd_idx])\n",
        "print(f'The sampled image represents a: {alphabet[y_val[rnd_idx]]}')\n",
        "plot_number(x_val[rnd_idx].reshape(28,28))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![evidencia3](https://i.imgur.com/ib5RsEY.jpg[/img])"
      ],
      "metadata": {
        "id": "YJiERWjgESxo"
      },
      "id": "YJiERWjgESxo"
    },
    {
      "cell_type": "markdown",
      "id": "668cfc56",
      "metadata": {
        "id": "668cfc56"
      },
      "source": [
        "### **The number model**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a18c833b",
      "metadata": {
        "id": "a18c833b"
      },
      "source": [
        "$$z^1 = W^1 X + b^1$$\n",
        "\n",
        "$$a^1 = ReLU(z^1) $$\n",
        "\n",
        "$$z^2 = W^2 a^1 + b^2$$\n",
        "\n",
        "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
        "\n",
        "\n",
        "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beae3ef9",
      "metadata": {
        "id": "beae3ef9"
      },
      "source": [
        "### **Create minibatches**\n",
        "\n",
        "It prepares data prior to training an ML model by dividing a large data set into smaller batches and optionally mixing them.\n",
        "\n",
        "With the following named function: **create_minibatches** Splits a data set (such as images (X) and their respective labels (y)) into smaller batches or \"mini-batches\". It is an optimization method called **minibatch stochastic gradient descent** (mini-batch stochastic gradient descent).\n",
        "\n",
        "La función create_minibatches toma cuatro argumentos:\n",
        "\n",
        "- **mb_size**: The size of the minibatch (how many samples we want per batch).\n",
        "- **x**: The input samples (e.g. images).\n",
        "- **y**: The labels corresponding to the input samples.\n",
        "- **shuffle**: An optional parameter that indicates if we want to shuffle the data before creating the minibatches. By default, it is set to true"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "id": "780beecf",
      "metadata": {
        "id": "780beecf"
      },
      "outputs": [],
      "source": [
        "def create_minibatches(mb_size, x, y, shuffle = True):\n",
        "    '''\n",
        "    x  #muestras, 784\n",
        "    y #muestras, 1\n",
        "    '''\n",
        "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
        "    total_data = x.shape[0]\n",
        "\n",
        "    #Data blending (if shuffle is true)\n",
        "    if shuffle:\n",
        "        idxs = np.arange(total_data)\n",
        "        np.random.shuffle(idxs)\n",
        "        x = x[idxs]\n",
        "        y = y[idxs]\n",
        "\n",
        "    #Generate and return minibatches:\n",
        "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "id": "4b8f845e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4b8f845e",
        "outputId": "8db210fe-b02d-4841-9d25-b60a9a457832"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n",
            "175\n",
            "176\n",
            "177\n",
            "178\n",
            "179\n",
            "180\n",
            "181\n",
            "182\n",
            "183\n",
            "184\n",
            "185\n",
            "186\n",
            "187\n",
            "188\n",
            "189\n",
            "190\n",
            "191\n",
            "192\n",
            "193\n",
            "194\n",
            "195\n",
            "196\n",
            "197\n",
            "198\n",
            "199\n",
            "200\n",
            "201\n",
            "202\n",
            "203\n",
            "204\n",
            "205\n",
            "206\n",
            "207\n",
            "208\n",
            "209\n",
            "210\n",
            "211\n",
            "212\n",
            "213\n",
            "214\n"
          ]
        }
      ],
      "source": [
        "for i, (x, y) in enumerate(create_minibatches(128,x_train, y_train)): #Return a list (or some kind of iterable) of minibatches, where each minibatch is a pair of data (x, y).\n",
        "    print(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12273997",
      "metadata": {
        "id": "12273997"
      },
      "source": [
        "### **Now the PyTorch part**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "id": "cbd1415d",
      "metadata": {
        "id": "cbd1415d"
      },
      "outputs": [],
      "source": [
        "#Tensors are created for each training, validation and test data set.\n",
        "x_train_tensor = torch.tensor(x_train.copy())\n",
        "y_train_tensor = torch.tensor(y_train.copy())\n",
        "\n",
        "x_val_tensor = torch.tensor(x_val.copy())\n",
        "y_val_tensor = torch.tensor(y_val.copy())\n",
        "\n",
        "x_test_tensor = torch.tensor(x_test.copy())\n",
        "y_test_tensor = torch.tensor(y_test.copy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "id": "087285a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "087285a9",
        "outputId": "049d1d51-a4b4-4fcf-b998-f512645a1e1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "#Validation of the device on which the models are to be trained\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "823c3ba5",
      "metadata": {
        "id": "823c3ba5"
      },
      "source": [
        "## **Accuracy**\n",
        "\n",
        "If we want to measure the performance of a model after training it or during its validation, the combination between accuracy and cost provides a complete view of the behavior of our models, with this we could make decisions that allow us to improve it if it is the case or give it the use if it is ready.\n",
        "\n",
        "According to what the professor says in the video we could say the following:\n",
        "\n",
        "The **accuracy function** evaluates the performance of a model using four parameters: the model itself, the dataset inputs, the actual labels and the minibatch size. It starts by initializing counters and an accumulator to monitor correct predictions, total predictions and cost respectively. The model is put into evaluation mode and transferred to the appropriate device, such as a GPU. ***During the evaluation, no gradients are calculated to optimize efficiency.\n",
        "\n",
        "In the process, **minibatches are used to compare the model predictions with the actual labels**, thus calculating **accuracy and cost**. Finally, the function **provides the average cost and accuracy to get a clear idea of the model performance**, being useful for post-training reviews or validations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "id": "e2e0f02a",
      "metadata": {
        "id": "e2e0f02a"
      },
      "outputs": [],
      "source": [
        "def accuracy(model, x, y, mb_size):\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    cost = 0.\n",
        "    model.eval()\n",
        "    model = model.to(device=device)\n",
        "    with torch.no_grad():\n",
        "        for mb, (xi, yi) in enumerate(create_minibatches(mb_size, x, y),1):\n",
        "            xi = xi.to(device=device, dtype = torch.float32)\n",
        "            yi = yi.to(device=device, dtype = torch.long)\n",
        "            scores = model(xi) # mb_size, 10\n",
        "            cost += (F.cross_entropy(scores, yi)).item()\n",
        "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
        "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
        "            num_total += pred.size(0)\n",
        "\n",
        "        return cost/mb, float(num_correct)/num_total"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "533c2954",
      "metadata": {
        "id": "533c2954"
      },
      "source": [
        "### **Training Loop**\n",
        "- Basic structure for training deep learning models in PyTorch\n",
        "\n",
        "Train function:\n",
        "\n",
        "This function trains a model given an optimizer, a minibatch size and a number of epochs.\n",
        "\n",
        "**Parameters**:\n",
        "\n",
        "- **model**: the model to train.\n",
        "- **optimizer**: the optimizer to use (e.g. SGD, Adam, etc.).\n",
        "- **mb_size**: size of the minibatch (number of examples to be processed at a time).\n",
        "- **epochs**: number of times the algorithm must traverse the whole training set. It has a default value of 100.\n",
        "\n",
        "- **Move the model to the device:** model = model.to(device=)\n",
        "\n",
        "- **model** = model.to(device=device): This moves the model to the specified device (usually CPU or GPU) for faster computations in case of a GPU.\n",
        "\n",
        "**Variable initialization:**\n",
        "\n",
        "- Some variables are initialized to keep track of the cost and performance of the model.\n",
        "\n",
        "**Training loop:**\n",
        "\n",
        "- Iterates over a specified number of epochs.\n",
        "Within each epoch, iterate over the minibatches of the training set.\n",
        "\n",
        "**Data preparation:**\n",
        "\n",
        "- Data is moved from the minibatch to the minibatch.\n",
        "- The minibatch data is moved to the appropriate device and matched to the correct data types.\n",
        "\n",
        "**Forward step:**\n",
        "\n",
        "- Data is passed through the model to obtain scores, which are the model's predictions.\n",
        "\n",
        "**Cost calculation:** Cross entropy is used as a cost function.\n",
        "\n",
        "**Backpropagation:**\n",
        "\n",
        "- Gradients are set to zero (this is necessary because PyTorch accumulates gradients).\n",
        "Backpropagate the gradients using cost.backward().\n",
        "Update the model weights with optimiser.step().\n",
        "\n",
        "**Countability:**\n",
        "\n",
        "- The number of correct predictions is calculated and added to the total number of examples processed.\n",
        "The cost is accumulated.\n",
        "\n",
        "**Validation:**\n",
        "\n",
        "- Once all minibatches in an epoch have been iterated over, the performance of the model is evaluated on a validation set.\n",
        "\n",
        "**Metrics printing:**\n",
        "\n",
        "- Every 20 epochs, metrics such as cost and accuracy are printed on the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "id": "6d0e44c7",
      "metadata": {
        "id": "6d0e44c7"
      },
      "outputs": [],
      "source": [
        "def train(model, optimiser, mb_size, epochs=100):\n",
        "    model = model.to(device=device)\n",
        "    train_cost = 0.\n",
        "    val_cost = 0.\n",
        "    for epoch in range(epochs):\n",
        "        train_correct_num  = 0.\n",
        "        train_total = 0.\n",
        "        train_cost_acum = 0\n",
        "        for mb, (xi, yi) in enumerate(create_minibatches(mb_size, x_train_tensor, y_train_tensor), 1):\n",
        "            model.train()\n",
        "            xi = xi.to(device=device, dtype=torch.float32)\n",
        "            yi = yi.to(device=device, dtype=torch.long)\n",
        "            scores = model(xi)\n",
        "            # funcion cost\n",
        "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
        "            optimiser.zero_grad()\n",
        "            cost.backward()\n",
        "            optimiser.step()\n",
        "\n",
        "            train_correct_num += (torch.argmax(scores, dim=1) == yi.squeeze()).sum()\n",
        "            train_total += scores.size(0)\n",
        "\n",
        "            train_cost_acum += cost.item()\n",
        "\n",
        "        val_cost, val_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
        "        train_acc = float(train_correct_num)/train_total\n",
        "        train_cost = train_cost_acum/mb\n",
        "        if epoch%20 == 0:\n",
        "            print(f'Epoch:{epoch}, train cost: {train_cost:.6f}, val cost: {val_cost:.6f},'\n",
        "                      f' train acc: {train_acc:.4f}, val acc: {val_acc:4f},'\n",
        "                      f' lr: {optimiser.param_groups[0][\"lr\"]:.6f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "359b9243",
      "metadata": {
        "id": "359b9243"
      },
      "source": [
        "### **Model using Sequential**\n",
        "\n",
        "This phase is important, as the input and output layers must be stacked to form a complete network.\n",
        "\n",
        "- The following code defines a **simple neural network **with a **hidden layer**, configures it with an **optimizer** and a **learning rate scheduler**, and then **trains the model**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "id": "c3d678e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c3d678e9",
        "outputId": "0e081373-231a-4290-aa1c-8e83d5659135"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:0, train cost: 0.978656, val cost: 0.771776, train acc: 0.6972, val acc: 0.757390, lr: 0.004000\n",
            "Epoch:20, train cost: 0.131706, val cost: 0.776999, train acc: 0.9601, val acc: 0.792805, lr: 0.004000\n",
            "Epoch:40, train cost: 0.121335, val cost: 1.626490, train acc: 0.9645, val acc: 0.802844, lr: 0.004000\n",
            "Epoch:60, train cost: 0.102601, val cost: 0.866541, train acc: 0.9702, val acc: 0.815114, lr: 0.004000\n",
            "Epoch:80, train cost: 0.098929, val cost: 0.720581, train acc: 0.9697, val acc: 0.817345, lr: 0.004000\n"
          ]
        }
      ],
      "source": [
        "#Instantiate model\n",
        "# hidden1 = 100\n",
        "hidden = 500          #hidden layer with 200 neurons\n",
        "lr = 4e-3             #learning rate (lr) of 1 x 10-³ for the optimizer\n",
        "epochs = 100          #Number of epochs (complete passes through the training set) planned to train the model is 20.\n",
        "mb_size = 512         #Minibatch (or batch) size as 512. During training, the model will be trained with subsets of 512 examples at a time.\n",
        "\n",
        "#The neural model called model1 is defined using a sequential model.\n",
        "model1 = nn.Sequential(nn.Linear(in_features=784, out_features=hidden),     #A linear (or fully connected) layer that takes 784 input features and produces 200 output features (neurons).\n",
        "                       nn.Dropout(),                                        #A dropout layer to regularize the model and prevent overfitting.\n",
        "                       nn.ReLU(),                                           #A ReLU activation function\n",
        "                      #nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
        "                       nn.Linear(in_features=hidden, out_features=24))\n",
        "\n",
        "#Optimiser = torch.optim.SGD(model1.parameters(), lr=lr, momentum=0.9, weight_decay=1e-2)\n",
        "optimiser = torch.optim.Adam(model1.parameters(), lr=lr, weight_decay=1e-3)\n",
        "\n",
        "#Defines a learning rate scheduler that adjusts the learning rate during training.\n",
        "#In this case, the OneCycleLR policy is used with a max_lr of 0.1, and is expected to run for 20 epochs with 215 steps per epoch.\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser, 0.1, epochs=epochs, steps_per_epoch=215)\n",
        "\n",
        "#A train function is called to train the model using the optimizer, minibatch size and number of epochs defined above.\n",
        "train(model1, optimiser, mb_size, epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a first example, we have defined a neural network that has:\n",
        "\n",
        "\n",
        "- **hidden** = 200 #200 neurons\n",
        "- lr** = 1e-3 #learning rate (lr) of 1 x 10-³ for the optimizer\n",
        "- **epochs** = 20 #Number of epochs (complete passes through the training set) expected to train the model is 20.\n",
        "- Size_mb** = 512 #Size of the minibatch (or batch) as 512. During training, the model will be trained with subsets of 512 examples at a time.\n",
        "\n",
        "\n",
        "Between each layer, we use a **ReLU** activation function, although there are other options such as Sigmoid, Tanh, etc.\n",
        "\n",
        "\n",
        "Once the network was defined, we used a PyTorch **optimizers** such as **torch.optim.Adam**.\n",
        "\n",
        "\n",
        "- **Accuracy Result**: 0.7947573898494144\n",
        "\n",
        "-----\n",
        "\n",
        "- 200 #200 neurons\n",
        "- lr** = 6e-3 #learning rate (lr) of 6 x 10-³ for the optimizer.\n",
        "- **epochs** = 50 #Number of epochs (complete passes through the training set) expected to train the model is 50.\n",
        "- Size_mb** = 512 #Size of the minibatch (or batch) as 512. During training, the model will be trained with subsets of 512 examples at a time.\n",
        "\n",
        "\n",
        "Between each layer, we use a **ReLU** activation function, although there are other options such as Sigmoid, Tanh, etc.\n",
        "\n",
        "\n",
        "Once the network was defined, we used a PyTorch **optimizers** such as **torch.optim.Adam**.\n",
        "\n",
        "\n",
        "- **Accuracy Result**: 0.7590630228667038\n",
        "\n",
        "-----\n",
        "- 500 #500 neurons\n",
        "- **lr** = 4e-3 #learning rate (lr) of 4 x 10-³ for the optimizer\n",
        "- **epochs** = 100 #Number of epochs (complete passes through the training set) planned to train the model is 100.\n",
        "- **mb_size** = 512 #Minibatch (or batch) size as 512. During training, the model will be trained with subsets of 512 examples at a time.\n",
        "\n",
        "Between each layer, we use an activation function **ReLU**, although there are other options such as Sigmoid, Tanh, etc.\n",
        "\n",
        "and the parameter is changed to: **weight_decay=1e-2 to 1e-3**:\n",
        "\n",
        "*\"The weight_decay is a form of regularization. Specifically, it is the L2 regularization, which penalizes large values in the parameters to avoid overfitting. 1e-3 is equal to 0.001, which indicates the magnitude of this penalty.\" *.\n",
        "\n",
        "Once the network was defined, a PyTorch **optimizers** such as **torch.optim.Adam** was used.\n",
        "\n",
        "- **Accuracy result**: 0.8156720580033463\n",
        "-----\n",
        "**With other optimiser: SGD**\n",
        "\n",
        "- **hidden** = 500 #500 neurons\n",
        "- **lr** = 4e-3 #learning rate (lr) of 4 x 10-³ for the optimizer\n",
        "- **epochs** = 100 #Number of epochs (complete passes through the training set) planned to train the model is 50.\n",
        "- **mb_size** = 512 #Minibatch (or batch) size as 512. During training, the model will be trained with subsets of 512 examples at a time.\n",
        "\n",
        "Between each layer, we use a **ReLU** activation function, although there are other options such as Sigmoid, Tanh, etc.\n",
        "\n",
        "Once the network was defined, we used a PyTorch **optimizer** such as **torch.optim.SGD**.\n",
        "\n",
        "It is added **momentum** is a technique that helps to accelerate the SGD in the relevant direction and dampens oscillations. Its common value for testing models is 0.9.\n",
        "\n",
        "- **Accuracy score**: 0.7805354155047407\n"
      ],
      "metadata": {
        "id": "u8E-iK2ohjTq"
      },
      "id": "u8E-iK2ohjTq"
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "id": "c1942c3b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "c1942c3b",
        "outputId": "eb8ab2e0-9548-403d-de51-68e734830122"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8156720580033463"
            ]
          },
          "metadata": {},
          "execution_count": 217
        }
      ],
      "source": [
        "#The accuracy function is called\n",
        "accuracy(model1, x_test_tensor, y_test_tensor, mb_size)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Predictions of the model**\n",
        "\n",
        "This function takes an input and a model, and returns the predicted classes for that input using the given model\n"
      ],
      "metadata": {
        "id": "KxXRYqKGZ39J"
      },
      "id": "KxXRYqKGZ39J"
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "id": "6fa8f9d8",
      "metadata": {
        "id": "6fa8f9d8"
      },
      "outputs": [],
      "source": [
        "def predict(x, model):\n",
        "    x = x.to(device=device, dtype = torch.float32)        ##X = Represents the input data you want to predic\n",
        "    scores = model(x) # mb_size, 10                       ##Score for each possible class\n",
        "    _, pred = scores.max(dim=1) #pred shape (mb_size )    ##The method returns two values: the maximum values and the indices of those maximum values.\n",
        "    return pred                                           ##The function returns pred, which is a tensor with the predicted classes for each example in the batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "id": "bb4edc89",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "bb4edc89",
        "outputId": "efd49782-4378-4a1d-e6e2-75f4faac59a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sampled image represents a: f\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the predicted value f\n"
          ]
        }
      ],
      "source": [
        "rnd_idx = np.random.randint(len(y_test))\n",
        "print(f'The sampled image represents a: {alphabet[y_test[rnd_idx]]}')\n",
        "plot_number(x_test[rnd_idx].reshape(28,28))\n",
        "pred=predict(x_test_tensor[rnd_idx].reshape(1, -1), model1)\n",
        "print(f'the predicted value {alphabet[pred]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conclusions**\n",
        "\n",
        "- We could say that in this activity we worked with a simple neural network with a tool called PyTorch, which helps us to build that stack of neurons in a simpler way. In addition, it helps us to assemble the neurons so that they interact and it is a manageable machine at the time of processing the information, since the deeper it is or the more layers it has, the more complex and detailed it becomes.\n",
        "\n",
        "- **Working with the model**\n",
        "\n",
        "The results of the test with the Sequential model, were:\n",
        "\n",
        "* The model with lower layers and lower lr, ranged in accuracy from 0.75 to 0.77. However, tests were performed with low lr and in certain occasions the accuracy result was 0.80.\n",
        "\n",
        "* Some parameters such as the epochs made the performance improve a little, but the results were not higher.\n",
        "\n",
        "* Changing the number of hidden neurons did influence the change in the accuracy results, going from 0.77 to 0.80.\n",
        "\n",
        "* The change of the optimized Adam to SGD did not influence the results in a negative way, rather the results remained within the same ranges."
      ],
      "metadata": {
        "id": "kG-aKMQ4b3lB"
      },
      "id": "kG-aKMQ4b3lB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Bibliography**\n",
        "\n",
        "**Vídeos**\n",
        "\n",
        "* (Vídeo opcional) [Pepe Cantoral, Ph.D.]. (2021, 6 de julio). ¡Red Neuronal usando PyTorch! Tutorial de PyTorchEnlaces a un sitio externo.  [Archivo de vídeo]. YouTube\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 19 de marzo). Backpropagation - Gradient Descent, Ejemplo completo –Fundamentos de Deep Learning – (Parte 9)Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 27 de marzo). Funciones de Activación – Fundamentos de Deep Learning – (Parte 10) [Archivo de vídeo]Enlaces a un sitio externo.. [Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 31 de marzo). Redes Neuronales Multi-Capa / Deep Neural Networks – Fundamentos de Deep Learning -(Teoría parte 11)Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 15 de mayo). ¡Red Neuronal Desde Cero estilo FRAMEWORK de DEEP LEARNING!Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 18 de mayo). ¡Red Neuronal Desde Cero estilo FRAMEWORK de DEEP LEARNING - Parte 2!Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 11 de diciembre). Redes Neuronales Convolucionales / Convolutional Neural Networks (CNN) – Parte 1Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 13 de diciembre). Redes Neuronales Convolucionales / Convolutional Neural Networks (CNN) – Parte 2Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 17 de diciembre). Redes Neuronales Convolucionales / Convolutional Neural Networks (CNN) – Parte 3Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "* [Pepe Cantoral, Ph-D.]. (2021, 17 de diciembre). Redes Neuronales Convolucionales / Convolutional Neural Networks (CNN) – Parte 4Enlaces a un sitio externo.[Archivo de vídeo]. YouTube.\n",
        "\n",
        "**Books**\n",
        "\n",
        "* Raschka, S., Liu, Y. (., Mirjalili, V., Dzhulgakov, D. (2022). Aprendizaje automático con PyTorch y Scikit-Learn: desarrollo de modelos de aprendizaje automático y aprendizaje profundo con Python . Reino Unido: Packt Publishing.  \n",
        "Lea el Capítulo 14.\n",
        "\n",
        "**Documents**\n",
        "\n",
        "* Ioffe, S. y Szehedy, C. (2015). Normalización de lotes: acelerar el entrenamiento profundo de la red reduciendo el cambio de covariables internoEnlaces a un sitio externo..\n",
        "\n",
        "Este artículo presenta la normalización por lotes, un método para acelerar el entrenamiento y mejorar el rendimiento.\n",
        "\n",
        "* Él, K., Zhang, X., Ren, S. y Sun, J. (2015). Profundizando en los rectificadores: superando el rendimiento a nivel humano en la clasificación ImageNetEnlaces a un sitio externo..\n",
        "\n",
        "* Este artículo presenta un nuevo método para la inicialización de peso (inicialización He), que considera las\n",
        "no linealidades del rectificador para la inicialización profunda de la red."
      ],
      "metadata": {
        "id": "W8_ccb8ieu9Y"
      },
      "id": "W8_ccb8ieu9Y"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}